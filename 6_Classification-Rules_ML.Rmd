---
title: "Unit 6: Classification Rules"
subtitle: "Identifying Poisonous Mushrooms"
author: "Steven Ferguson"
date: "2022-09-29"
output: 
  rmdformats::downcute:
    downcute_theme: "chaos"
---

# Step 1 -- Collecting the Data

Eating mushrooms found in the wild can be dangerous. Many wild poisonous mushrooms have a similar appearance to edible mushrooms. There are no clear, simple, or consistent rules to identify wild mushrooms in the field. Consequently, identifying safe edible mushrooms in the wild is difficult, even for the most experienced foragers. Perhaps a rule-learning algorithm could generate easy to understand classification rules to determine whether a mushroom was poisonous or not.

From lecture slides:

"To identify rules for distinguishing poisonous mushrooms, we will utilize the Mushroom dataset by Jeff Schlimmer of Carnegie Mellon University. The raw dataset is available freely at the UCI Machine Learning Repository ([http://archive.ics.uci.edu/ml).](http://archive.ics.uci.edu/ml).) The dataset includes information on 8,124 mushroom samples from23 species of gilled mushrooms listed in Audubon Society Field Guide to North American Mushrooms (1981).In the Field Guide, each of the mushroom species is identified"definitely edible," "definitely poisonous," or "likely poisonous, and not recommended to be eaten." For the purposes of this dataset, the latter group was combined with the "definitely poisonous" group to make two classes: poisonous and edible (nonpoisonous )."

# Step 2 -- Exploring and Preparing the Data

```{r}

mushrooms <- read.csv("mushrooms.csv", stringsAsFactors = TRUE)

# examine the structure of the data frame
str(mushrooms)

# drop the veil_type feature
mushrooms$veil_type <- NULL

# examine the class distribution
table(mushrooms$type)

```

"We will consider the 81214 samples in the mushroom data to be an exhaustive set of all the possible wild mushrooms". This is an important assumption. Because this is a whole population, not a sample, we don't need to split data up into test and training datasets. We are not trying to develop rules that cover unforeseen types of Mushrooms.

# Step 3 -- Training a Model on the Data

We need to pick an algorithm for our model. A ZeroR algorithm would not be helpful. ZeroR ignores all features and simply predicts the mode of a target. It would see 4208 mushrooms were labeled "edible" and 3916 were labeled "poisonous". A zero rule algorithm, would false predict that every unknown mushroom was "edible" simply because there are more labeled edible mushrooms in the training dataset. That's an accuracy of 52% ! We can do much better than that.

A one rule algorithm analyzes the data and generates one all-encompassing rule. It works by finding the single rule that contains the least amount of error. Despite its simplicity, it is very accurate.

**Rule Learner Using the OneR() algorithm**

```{r}
#install.packages("OneR")
library(OneR)

# train OneR() on the data
mushroom_1R = OneR(type ~ ., data = mushrooms)

print(mushroom_1R)
```

A OneR algorithm is much more accurate: 98.52% ! These rules are very easy to understand. The algorithm found a significant pattern in the "odor" rule. If the odor was almond, anise, or "none", then it predicted the mushroom would be edible. It found that this pattern correctly identified 98.52% of the mushrooms. Just one rule! I'm surprised at how well this worked.

# Step 4 \-- Evaluating Model Performance

```{r}
mushroom_1R_pred <- predict(mushroom_1R, mushrooms)
table(actual = mushrooms$type, predicted = mushroom_1R_pred)
# DANGEROUS RULE. TOO MANY FALSE POSITIVES. 120 predicted edible, but actually poisonous
```

However, the One Rule algorithm did incorrectly predict a mushroom to be edible (when it was poisonous) on 120 occasions (false positive). Yes, the risk seems low (2.58%), but it's still unacceptably high considering the consequence of a false positive: potentially fatal poisoning. We can do better to limit these dangerous false positives.

# Step 5 -- Improving Model Performance

**RIPPER Algorithm using the JRip() Classifier**

Another common classification rule is the RIPPER Algorithm.

The ripper algorithm can create more complex rules than the OneR algorithm as it considers more than one feature of the dataset. The RIPPER algorithm adds conditions to a rule until it perfectly classifies a subset of data. It then prunes rules that no longer reducesentropy and optimizes the entire set of rules automatically by repeating steps 1 and 2 until reaching a stopping criterion. The three steps of the RIPPER algorithm can be summarized as "Grow, prune, optimize".

```{r}
detach("package:OneR", unload = TRUE)
#install.packages("RWeka")
library(RWeka) #GOOGLE WEKA AND LEARN ABOUT IT
mushroom_JRip <- JRip(type ~ ., data = mushrooms)
mushroom_JRip
summary(mushroom_JRip)
```

Indeed the RIPPER algorithm perfectly classified every instance (100% accuracy) antastic. However, the rules are now a bit more complicated to understand because they combine rules using "and/or" statements. 9 rules were used. Therefore, it's a little less straightforward, but still accessible.

This is how to read the rules: If the odor is "foul", then the mushroom is poisonous. If the stalk_surface_below_ring is scaly and the stalk_surface_above_ring is silky then the mushroom is poisonous. It took 9 rules to classify and separate all the poisonous mushrooms from the non-poisonous mushrooms. After nine rules, only non-poisonous mushrooms remained.

**Ruler Learner Using C5.0 Decision Trees**

```{r}
detach("package:RWeka", unload = TRUE) #OneR will not print if RWeka is attached
library(C50)
mushroom_c5rules <- C5.0(type~odor+gill_size,data=mushrooms,rules=TRUE)
summary(mushroom_c5rules)


```

The C5.0 classifier identified 2 if/then rules to classify the mushrooms with a 1.5% error rate. 120 false positives occurred. This happens to be the same result as the OneR algorithm. It actually used the same attributes in each rule as the OneR algorith, just formatted differently.
